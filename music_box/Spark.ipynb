{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# May take a little while on a local computer\n",
    "spark = SparkSession.builder.appName(\"music_box\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load play_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "play_path = '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/'\n",
    "play_list = []\n",
    "for fname in os.listdir(play_path):\n",
    "    play_list.append(play_path+fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/.DS_Store',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170401_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170401_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170401_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170402_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170402_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170402_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170403_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170403_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170404_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170404_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170405_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170405_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170405_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170406_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170406_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170406_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170407_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170407_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170407_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170408_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170408_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170408_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170409_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170409_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170409_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170410_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170410_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170410_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170411_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170411_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170412_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170412_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170412_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170413_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170413_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170413_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170414_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170414_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170414_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170415_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170415_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170415_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170416_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170416_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170416_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170417_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170417_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170417_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170418_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170418_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170418_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170419_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170419_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170419_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170420_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170420_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170420_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170421_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170421_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170421_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170422_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170422_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170422_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170423_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170423_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170423_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170424_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170424_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170424_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170425_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170425_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170425_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170426_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170426_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170426_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170427_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170427_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170427_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170428_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170428_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170428_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170429_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170429_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170429_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170430_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170430_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170430_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170501_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170501_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170501_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170502_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170502_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170502_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170503_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170503_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170503_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170504_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170504_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170504_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170505_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170505_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170505_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170506_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170506_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170506_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170507_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170507_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170507_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170508_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170508_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170508_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170509_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170509_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170509_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170510_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170510_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170510_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170511_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170511_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170511_3_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170512_1_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170512_2_play.csv',\n",
       " '/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/20170512_3_play.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load all play log:\n",
    "play_schema = StructType([ StructField(\"uid\",IntegerType(),nullable = False), \n",
    "                          StructField(\"new_device\", StringType()), \n",
    "                          StructField(\"song_id\",IntegerType()), \n",
    "                          StructField(\"new_play_time\", DoubleType()),\n",
    "                          StructField(\"new_song_length\", DoubleType()),\n",
    "                          StructField(\"date\", DateType())\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: integer (nullable = true)\n",
      " |-- new_device: string (nullable = true)\n",
      " |-- song_id: integer (nullable = true)\n",
      " |-- new_play_time: double (nullable = true)\n",
      " |-- new_song_length: double (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n",
      "Total Rows: 98039208\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(play_list)):\n",
    "    if i == 0:\n",
    "        df_play = spark.read.csv(play_list[i],sep = '|', header = True, schema = play_schema, encoding = 'UTF-8')\n",
    "    else:\n",
    "        df_play_merge = spark.read.csv(play_list[i],sep = '|', header = True, schema = play_schema, encoding = 'UTF-8')\n",
    "        df_play = df_play.unionAll(df_play_merge)\n",
    "\n",
    "df_play.printSchema()\n",
    "\n",
    "print (\"Total Rows: \" + str(df_play.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+-------------+---------------+----------+\n",
      "|      uid|new_device|song_id|new_play_time|new_song_length|      date|\n",
      "+---------+----------+-------+-------------+---------------+----------+\n",
      "| 38830551|        ar|1152372|        171.0|          172.0|2017-04-01|\n",
      "|167923158|        ar| 985228|        251.0|          251.0|2017-04-01|\n",
      "|168045107|        ar|6818758|          0.0|         1683.0|2017-04-01|\n",
      "|168024853|        ar|3971731|        300.0|          300.0|2017-04-01|\n",
      "|167580792|        ar|6989313|        113.0|          113.0|2017-04-01|\n",
      "+---------+----------+-------+-------------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_play.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_play = df_play.withColumn('mon',month(df_play['date']))\n",
    "df_play = df_play.withColumn('dayofMon',dayofmonth(df_play['date']))\n",
    "df_play = df_play.withColumn('3dayofMon',(dayofmonth(df_play['date'])-1)/3)\n",
    "df_play = df_play.withColumn('5dayofMon',(dayofmonth(df_play['date'])-1)/5)\n",
    "df_play = df_play.withColumn('7dayofMon',(dayofmonth(df_play['date'])-1)/7)\n",
    "df_play = df_play.withColumn('14dayofMon',(dayofmonth(df_play['date'])-1)/14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+-------------+---------------+----------+---+--------+---------+---------+---------+----------+\n",
      "|      uid|new_device|song_id|new_play_time|new_song_length|      date|mon|dayofMon|3dayofMon|5dayofMon|7dayofMon|14dayofMon|\n",
      "+---------+----------+-------+-------------+---------------+----------+---+--------+---------+---------+---------+----------+\n",
      "| 38830551|        ar|1152372|        171.0|          172.0|2017-04-01|  4|       1|      0.0|      0.0|      0.0|       0.0|\n",
      "|167923158|        ar| 985228|        251.0|          251.0|2017-04-01|  4|       1|      0.0|      0.0|      0.0|       0.0|\n",
      "|168045107|        ar|6818758|          0.0|         1683.0|2017-04-01|  4|       1|      0.0|      0.0|      0.0|       0.0|\n",
      "|168024853|        ar|3971731|        300.0|          300.0|2017-04-01|  4|       1|      0.0|      0.0|      0.0|       0.0|\n",
      "|167580792|        ar|6989313|        113.0|          113.0|2017-04-01|  4|       1|      0.0|      0.0|      0.0|       0.0|\n",
      "+---------+----------+-------+-------------+---------------+----------+---+--------+---------+---------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_play.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## freq_1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_play_Apr = df_play.filter(df_play['mon']==4)\n",
    "df_play_May = df_play.filter(df_play['mon']==5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_1d = df_play_Apr.groupBy('uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_1d_song = gb_1d.agg({'song_id':'count'}).alias('song')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_1d_playtime = gb_1d.agg({'new_play_time':'sum'}).alias('playtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_final = freq_1d_song.join(freq_1d_playtime,col('song.uid') == col('playtime.uid'),'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_final = df_final.withColumn('freq_1d_song',df_final['count(song_id)']/30)\n",
    "df_final = df_final.withColumn('freq_1d_playtime',df_final['sum(new_play_time)']/30)\n",
    "df_final = df_final.select(['song.uid','freq_1d_song','freq_1d_playtime']).alias('final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## freq_3d, freq_5d, freq_7d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_3d_song = df_play_Apr.groupBy(['uid','3dayofMon']).agg({'song_id':'count'}).groupBy('uid').agg({'count(song_id)':'sum'}).alias('3dsong')\n",
    "df_3d_play = df_play_Apr.groupBy(['uid','3dayofMon']).agg({'new_play_time':'sum'}).groupBy('uid').agg({'sum(new_play_time)':'sum'}).alias('3dplay')\n",
    "\n",
    "df_temp = df_3d_song.join(df_3d_play,col('3dsong.uid') == col('3dplay.uid'),'inner')\n",
    "df_temp = df_temp.withColumn('freq_3d_song',df_temp['sum(count(song_id))']/10)\n",
    "df_temp = df_temp.withColumn('freq_3d_playtime',df_temp['sum(sum(new_play_time))']/10)\n",
    "df_temp = df_temp.select(['3dsong.uid','freq_3d_song','freq_3d_playtime']).alias('3d')\n",
    "df_final = df_final.join(df_temp,col('final.uid')==col('3d.uid'),'inner').select(['final.uid','freq_1d_song','freq_1d_playtime','freq_3d_song','freq_3d_playtime']).alias('final')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_5d_song = df_play_Apr.groupBy(['uid','5dayofMon']).agg({'song_id':'count'}).groupBy('uid').agg({'count(song_id)':'sum'}).alias('5dsong')\n",
    "df_5d_play = df_play_Apr.groupBy(['uid','5dayofMon']).agg({'new_play_time':'sum'}).groupBy('uid').agg({'sum(new_play_time)':'sum'}).alias('5dplay')\n",
    "\n",
    "df_temp = df_5d_song.join(df_5d_play,col('5dsong.uid') == col('5dplay.uid'),'inner')\n",
    "df_temp = df_temp.withColumn('freq_5d_song',df_temp['sum(count(song_id))']/6)\n",
    "df_temp = df_temp.withColumn('freq_5d_playtime',df_temp['sum(sum(new_play_time))']/6)\n",
    "df_temp = df_temp.select(['5dsong.uid','freq_5d_song','freq_5d_playtime']).alias('5d')\n",
    "df_final = df_final.join(df_temp,col('final.uid')==col('5d.uid'),'inner').select(['final.uid','freq_1d_song','freq_1d_playtime','freq_3d_song','freq_3d_playtime','freq_5d_song','freq_5d_playtime']).alias('final')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_7d_song = df_play_Apr.groupBy(['uid','7dayofMon']).agg({'song_id':'count'}).groupBy('uid').agg({'count(song_id)':'sum'}).alias('7dsong')\n",
    "df_7d_play = df_play_Apr.groupBy(['uid','7dayofMon']).agg({'new_play_time':'sum'}).groupBy('uid').agg({'sum(new_play_time)':'sum'}).alias('7dplay')\n",
    "\n",
    "df_temp = df_7d_song.join(df_7d_play,col('7dsong.uid') == col('7dplay.uid'),'inner')\n",
    "df_temp = df_temp.withColumn('freq_7d_song',df_temp['sum(count(song_id))']/4)\n",
    "df_temp = df_temp.withColumn('freq_7d_playtime',df_temp['sum(sum(new_play_time))']/4)\n",
    "df_temp = df_temp.select(['7dsong.uid','freq_7d_song','freq_7d_playtime']).alias('7d')\n",
    "df_final = df_final.join(df_temp,col('final.uid')==col('7d.uid'),'inner').select(['final.uid','freq_1d_song','freq_1d_playtime','freq_3d_song','freq_3d_playtime','freq_5d_song','freq_5d_playtime','freq_7d_song','freq_7d_playtime']).alias('final')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+------------------+------------+----------------+------------------+------------------+------------+----------------+\n",
      "|     uid|       freq_1d_song|  freq_1d_playtime|freq_3d_song|freq_3d_playtime|      freq_5d_song|  freq_5d_playtime|freq_7d_song|freq_7d_playtime|\n",
      "+--------+-------------------+------------------+------------+----------------+------------------+------------------+------------+----------------+\n",
      "|10906795|0.16666666666666666|40.166666666666664|         0.5|           120.5|0.8333333333333334|200.83333333333334|        1.25|          301.25|\n",
      "|13277485| 0.5333333333333333|46.233333333333334|         1.6|           138.7|2.6666666666666665|231.16666666666666|         4.0|          346.75|\n",
      "|13610475| 49.666666666666664|            3006.6|       149.0|          9019.8|248.33333333333334|           15033.0|       372.5|         22549.5|\n",
      "|20974764|                1.9|             226.1|         5.7|           678.3|               9.5|            1130.5|       14.25|         1695.75|\n",
      "|34509854|0.36666666666666664|193.43333333333334|         1.1|           580.3|1.8333333333333333| 967.1666666666666|        2.75|         1450.75|\n",
      "+--------+-------------------+------------------+------------+----------------+------------------+------------------+------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429392"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_final.write.save('play_log_freq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_play_May = df_play.filter(df_play['mon']==5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+-------------+---------------+----------+---+--------+---------+---------+---------+----------+\n",
      "|      uid|new_device|song_id|new_play_time|new_song_length|      date|mon|dayofMon|3dayofMon|5dayofMon|7dayofMon|14dayofMon|\n",
      "+---------+----------+-------+-------------+---------------+----------+---+--------+---------+---------+---------+----------+\n",
      "|167942200|        ar| 442218|        260.0|          260.0|2017-05-01|  5|       1|      0.0|      0.0|      0.0|       0.0|\n",
      "|167682905|        ar| 440614|          4.0|          253.0|2017-05-01|  5|       1|      0.0|      0.0|      0.0|       0.0|\n",
      "|168009486|        ar| 157606|        288.0|          288.0|2017-05-01|  5|       1|      0.0|      0.0|      0.0|       0.0|\n",
      "|168022196|        ar| 835317|          3.0|          260.0|2017-05-01|  5|       1|      0.0|      0.0|      0.0|       0.0|\n",
      "|167879980|        ar|  90861|        300.0|          300.0|2017-05-01|  5|       1|      0.0|      0.0|      0.0|       0.0|\n",
      "+---------+----------+-------+-------------+---------------+----------+---+--------+---------+---------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_play_May.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_used = df_play_May.select('uid').alias('active')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|      uid|\n",
      "+---------+\n",
      "|167942200|\n",
      "|167682905|\n",
      "|168009486|\n",
      "|168022196|\n",
      "|167879980|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_used.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = df_final.join(df_used,col('final.uid') == col('active.uid'),'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+------------------+------------+----------------+------------------+------------------+------------+----------------+--------+\n",
      "|     uid|       freq_1d_song|  freq_1d_playtime|freq_3d_song|freq_3d_playtime|      freq_5d_song|  freq_5d_playtime|freq_7d_song|freq_7d_playtime|     uid|\n",
      "+--------+-------------------+------------------+------------+----------------+------------------+------------------+------------+----------------+--------+\n",
      "|10906795|0.16666666666666666|40.166666666666664|         0.5|           120.5|0.8333333333333334|200.83333333333334|        1.25|          301.25|    null|\n",
      "|13277485| 0.5333333333333333|46.233333333333334|         1.6|           138.7|2.6666666666666665|231.16666666666666|         4.0|          346.75|    null|\n",
      "|13610475| 49.666666666666664|            3006.6|       149.0|          9019.8|248.33333333333334|           15033.0|       372.5|         22549.5|13610475|\n",
      "|13610475| 49.666666666666664|            3006.6|       149.0|          9019.8|248.33333333333334|           15033.0|       372.5|         22549.5|13610475|\n",
      "|13610475| 49.666666666666664|            3006.6|       149.0|          9019.8|248.33333333333334|           15033.0|       372.5|         22549.5|13610475|\n",
      "+--------+-------------------+------------------+------------+----------------+------------------+------------------+------------+----------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce  # For Python 3.x\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def unionAll(*dfs):\n",
    "    return reduce(DataFrame.unionAll, dfs) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = test.where(col('active.uid').isNotNull())\n",
    "df2 = test.where(col('active.uid').isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df1.withColumn('label',lit(1))\n",
    "df2 = df2.withColumn('label',lit(0))\n",
    "res = unionAll(*[df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = res.select(['final.uid','freq_1d_song','freq_1d_playtime','freq_3d_song','freq_3d_playtime','freq_5d_song','freq_5d_playtime','freq_7d_song','freq_7d_playtime','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+----------------+------------+----------------+------------------+----------------+------------+----------------+-----+\n",
      "|     uid|      freq_1d_song|freq_1d_playtime|freq_3d_song|freq_3d_playtime|      freq_5d_song|freq_5d_playtime|freq_7d_song|freq_7d_playtime|label|\n",
      "+--------+------------------+----------------+------------+----------------+------------------+----------------+------------+----------------+-----+\n",
      "|13610475|49.666666666666664|          3006.6|       149.0|          9019.8|248.33333333333334|         15033.0|       372.5|         22549.5|    1|\n",
      "|13610475|49.666666666666664|          3006.6|       149.0|          9019.8|248.33333333333334|         15033.0|       372.5|         22549.5|    1|\n",
      "|13610475|49.666666666666664|          3006.6|       149.0|          9019.8|248.33333333333334|         15033.0|       372.5|         22549.5|    1|\n",
      "|13610475|49.666666666666664|          3006.6|       149.0|          9019.8|248.33333333333334|         15033.0|       372.5|         22549.5|    1|\n",
      "|13610475|49.666666666666664|          3006.6|       149.0|          9019.8|248.33333333333334|         15033.0|       372.5|         22549.5|    1|\n",
      "+--------+------------------+----------------+------------+----------------+------------------+----------------+------------+----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: integer (nullable = true)\n",
      " |-- freq_1d_song: double (nullable = true)\n",
      " |-- freq_1d_playtime: double (nullable = true)\n",
      " |-- freq_3d_song: double (nullable = true)\n",
      " |-- freq_3d_playtime: double (nullable = true)\n",
      " |-- freq_5d_song: double (nullable = true)\n",
      " |-- freq_5d_playtime: double (nullable = true)\n",
      " |-- freq_7d_song: double (nullable = true)\n",
      " |-- freq_7d_playtime: double (nullable = true)\n",
      " |-- label: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transform to a dataframe can be used by ml lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uid',\n",
       " 'freq_1d_song',\n",
       " 'freq_1d_playtime',\n",
       " 'freq_3d_song',\n",
       " 'freq_3d_playtime',\n",
       " 'freq_5d_song',\n",
       " 'freq_5d_playtime',\n",
       " 'freq_7d_song',\n",
       " 'freq_7d_playtime',\n",
       " 'label']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:53312)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\", line 852, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\", line 990, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:53312)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_connected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-c04926c67204>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m  \u001b[0;34m'freq_7d_song'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m  'freq_7d_playtime'],\n\u001b[0;32m---> 10\u001b[0;31m               outputCol=\"features\")\n\u001b[0m",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/pyspark/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method %s forces keyword arguments.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/pyspark/ml/feature.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputCols, outputCol)\u001b[0m\n\u001b[1;32m   2612\u001b[0m         \"\"\"\n\u001b[1;32m   2613\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVectorAssembler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2614\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_java_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"org.apache.spark.ml.feature.VectorAssembler\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2615\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2616\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_new_java_obj\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjava_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFLECTION_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m             \"\\n\" + proto.END_COMMAND_PART)\n\u001b[0m\u001b[1;32m   1553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUCCESS_PACKAGE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mJavaPackage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjvm_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    904\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \"\"\"\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    858\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    859\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 860\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    995\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:53312)"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "  inputCols=['freq_1d_song',\n",
    " 'freq_1d_playtime',\n",
    " 'freq_3d_song',\n",
    " 'freq_3d_playtime',\n",
    " 'freq_5d_song',\n",
    " 'freq_5d_playtime',\n",
    " 'freq_7d_song',\n",
    " 'freq_7d_playtime'],\n",
    "              outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = assembler.transform(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:53312)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\", line 852, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\", line 990, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:53312)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_connected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-199-9c69a1949e6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \"\"\"\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1160\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    904\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \"\"\"\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    858\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    859\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 860\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    995\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:53312)"
     ]
    }
   ],
   "source": [
    "output.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_data = output.select(\"features\",'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data,test_data = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o5116.showString.\n: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:\nExchange hashpartitioning(uid#2237, 200)\n+- *(125) HashAggregate(keys=[uid#2237], functions=[partial_count(song_id#2239)], output=[uid#2237, count#22433L])\n   +- Union\n      :- *(1) Project [uid#2237, song_id#2239]\n      :  +- *(1) Filter ((month(date#2242) = 4) && isnotnull(uid#2237))\n      :     +- *(1) FileScan csv [uid#2237,song_id#2239,date#2242] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(2) Project [uid#2249, song_id#2251]\n      :  +- *(2) Filter ((month(date#2254) = 4) && isnotnull(uid#2249))\n      :     +- *(2) FileScan csv [uid#2249,song_id#2251,date#2254] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(3) Project [uid#2267, song_id#2269]\n      :  +- *(3) Filter ((month(date#2272) = 4) && isnotnull(uid#2267))\n      :     +- *(3) FileScan csv [uid#2267,song_id#2269,date#2272] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(4) Project [uid#2285, song_id#2287]\n      :  +- *(4) Filter ((month(date#2290) = 4) && isnotnull(uid#2285))\n      :     +- *(4) FileScan csv [uid#2285,song_id#2287,date#2290] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(5) Project [uid#2303, song_id#2305]\n      :  +- *(5) Filter ((month(date#2308) = 4) && isnotnull(uid#2303))\n      :     +- *(5) FileScan csv [uid#2303,song_id#2305,date#2308] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(6) Project [uid#2321, song_id#2323]\n      :  +- *(6) Filter ((month(date#2326) = 4) && isnotnull(uid#2321))\n      :     +- *(6) FileScan csv [uid#2321,song_id#2323,date#2326] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(7) Project [uid#2339, song_id#2341]\n      :  +- *(7) Filter ((month(date#2344) = 4) && isnotnull(uid#2339))\n      :     +- *(7) FileScan csv [uid#2339,song_id#2341,date#2344] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(8) Project [uid#2357, song_id#2359]\n      :  +- *(8) Filter ((month(date#2362) = 4) && isnotnull(uid#2357))\n      :     +- *(8) FileScan csv [uid#2357,song_id#2359,date#2362] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(9) Project [uid#2375, song_id#2377]\n      :  +- *(9) Filter ((month(date#2380) = 4) && isnotnull(uid#2375))\n      :     +- *(9) FileScan csv [uid#2375,song_id#2377,date#2380] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(10) Project [uid#2393, song_id#2395]\n      :  +- *(10) Filter ((month(date#2398) = 4) && isnotnull(uid#2393))\n      :     +- *(10) FileScan csv [uid#2393,song_id#2395,date#2398] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(11) Project [uid#2411, song_id#2413]\n      :  +- *(11) Filter ((month(date#2416) = 4) && isnotnull(uid#2411))\n      :     +- *(11) FileScan csv [uid#2411,song_id#2413,date#2416] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(12) Project [uid#2429, song_id#2431]\n      :  +- *(12) Filter ((month(date#2434) = 4) && isnotnull(uid#2429))\n      :     +- *(12) FileScan csv [uid#2429,song_id#2431,date#2434] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(13) Project [uid#2447, song_id#2449]\n      :  +- *(13) Filter ((month(date#2452) = 4) && isnotnull(uid#2447))\n      :     +- *(13) FileScan csv [uid#2447,song_id#2449,date#2452] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(14) Project [uid#2465, song_id#2467]\n      :  +- *(14) Filter ((month(date#2470) = 4) && isnotnull(uid#2465))\n      :     +- *(14) FileScan csv [uid#2465,song_id#2467,date#2470] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(15) Project [uid#2483, song_id#2485]\n      :  +- *(15) Filter ((month(date#2488) = 4) && isnotnull(uid#2483))\n      :     +- *(15) FileScan csv [uid#2483,song_id#2485,date#2488] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(16) Project [uid#2501, song_id#2503]\n      :  +- *(16) Filter ((month(date#2506) = 4) && isnotnull(uid#2501))\n      :     +- *(16) FileScan csv [uid#2501,song_id#2503,date#2506] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(17) Project [uid#2519, song_id#2521]\n      :  +- *(17) Filter ((month(date#2524) = 4) && isnotnull(uid#2519))\n      :     +- *(17) FileScan csv [uid#2519,song_id#2521,date#2524] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(18) Project [uid#2537, song_id#2539]\n      :  +- *(18) Filter ((month(date#2542) = 4) && isnotnull(uid#2537))\n      :     +- *(18) FileScan csv [uid#2537,song_id#2539,date#2542] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(19) Project [uid#2555, song_id#2557]\n      :  +- *(19) Filter ((month(date#2560) = 4) && isnotnull(uid#2555))\n      :     +- *(19) FileScan csv [uid#2555,song_id#2557,date#2560] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(20) Project [uid#2573, song_id#2575]\n      :  +- *(20) Filter ((month(date#2578) = 4) && isnotnull(uid#2573))\n      :     +- *(20) FileScan csv [uid#2573,song_id#2575,date#2578] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(21) Project [uid#2591, song_id#2593]\n      :  +- *(21) Filter ((month(date#2596) = 4) && isnotnull(uid#2591))\n      :     +- *(21) FileScan csv [uid#2591,song_id#2593,date#2596] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(22) Project [uid#2609, song_id#2611]\n      :  +- *(22) Filter ((month(date#2614) = 4) && isnotnull(uid#2609))\n      :     +- *(22) FileScan csv [uid#2609,song_id#2611,date#2614] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(23) Project [uid#2627, song_id#2629]\n      :  +- *(23) Filter ((month(date#2632) = 4) && isnotnull(uid#2627))\n      :     +- *(23) FileScan csv [uid#2627,song_id#2629,date#2632] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(24) Project [uid#2645, song_id#2647]\n      :  +- *(24) Filter ((month(date#2650) = 4) && isnotnull(uid#2645))\n      :     +- *(24) FileScan csv [uid#2645,song_id#2647,date#2650] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(25) Project [uid#2663, song_id#2665]\n      :  +- *(25) Filter ((month(date#2668) = 4) && isnotnull(uid#2663))\n      :     +- *(25) FileScan csv [uid#2663,song_id#2665,date#2668] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(26) Project [uid#2681, song_id#2683]\n      :  +- *(26) Filter ((month(date#2686) = 4) && isnotnull(uid#2681))\n      :     +- *(26) FileScan csv [uid#2681,song_id#2683,date#2686] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(27) Project [uid#2699, song_id#2701]\n      :  +- *(27) Filter ((month(date#2704) = 4) && isnotnull(uid#2699))\n      :     +- *(27) FileScan csv [uid#2699,song_id#2701,date#2704] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(28) Project [uid#2717, song_id#2719]\n      :  +- *(28) Filter ((month(date#2722) = 4) && isnotnull(uid#2717))\n      :     +- *(28) FileScan csv [uid#2717,song_id#2719,date#2722] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(29) Project [uid#2735, song_id#2737]\n      :  +- *(29) Filter ((month(date#2740) = 4) && isnotnull(uid#2735))\n      :     +- *(29) FileScan csv [uid#2735,song_id#2737,date#2740] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(30) Project [uid#2753, song_id#2755]\n      :  +- *(30) Filter ((month(date#2758) = 4) && isnotnull(uid#2753))\n      :     +- *(30) FileScan csv [uid#2753,song_id#2755,date#2758] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(31) Project [uid#2771, song_id#2773]\n      :  +- *(31) Filter ((month(date#2776) = 4) && isnotnull(uid#2771))\n      :     +- *(31) FileScan csv [uid#2771,song_id#2773,date#2776] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(32) Project [uid#2789, song_id#2791]\n      :  +- *(32) Filter ((month(date#2794) = 4) && isnotnull(uid#2789))\n      :     +- *(32) FileScan csv [uid#2789,song_id#2791,date#2794] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(33) Project [uid#2807, song_id#2809]\n      :  +- *(33) Filter ((month(date#2812) = 4) && isnotnull(uid#2807))\n      :     +- *(33) FileScan csv [uid#2807,song_id#2809,date#2812] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(34) Project [uid#2825, song_id#2827]\n      :  +- *(34) Filter ((month(date#2830) = 4) && isnotnull(uid#2825))\n      :     +- *(34) FileScan csv [uid#2825,song_id#2827,date#2830] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(35) Project [uid#2843, song_id#2845]\n      :  +- *(35) Filter ((month(date#2848) = 4) && isnotnull(uid#2843))\n      :     +- *(35) FileScan csv [uid#2843,song_id#2845,date#2848] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(36) Project [uid#2861, song_id#2863]\n      :  +- *(36) Filter ((month(date#2866) = 4) && isnotnull(uid#2861))\n      :     +- *(36) FileScan csv [uid#2861,song_id#2863,date#2866] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(37) Project [uid#2879, song_id#2881]\n      :  +- *(37) Filter ((month(date#2884) = 4) && isnotnull(uid#2879))\n      :     +- *(37) FileScan csv [uid#2879,song_id#2881,date#2884] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(38) Project [uid#2897, song_id#2899]\n      :  +- *(38) Filter ((month(date#2902) = 4) && isnotnull(uid#2897))\n      :     +- *(38) FileScan csv [uid#2897,song_id#2899,date#2902] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(39) Project [uid#2915, song_id#2917]\n      :  +- *(39) Filter ((month(date#2920) = 4) && isnotnull(uid#2915))\n      :     +- *(39) FileScan csv [uid#2915,song_id#2917,date#2920] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(40) Project [uid#2933, song_id#2935]\n      :  +- *(40) Filter ((month(date#2938) = 4) && isnotnull(uid#2933))\n      :     +- *(40) FileScan csv [uid#2933,song_id#2935,date#2938] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(41) Project [uid#2951, song_id#2953]\n      :  +- *(41) Filter ((month(date#2956) = 4) && isnotnull(uid#2951))\n      :     +- *(41) FileScan csv [uid#2951,song_id#2953,date#2956] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(42) Project [uid#2969, song_id#2971]\n      :  +- *(42) Filter ((month(date#2974) = 4) && isnotnull(uid#2969))\n      :     +- *(42) FileScan csv [uid#2969,song_id#2971,date#2974] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(43) Project [uid#2987, song_id#2989]\n      :  +- *(43) Filter ((month(date#2992) = 4) && isnotnull(uid#2987))\n      :     +- *(43) FileScan csv [uid#2987,song_id#2989,date#2992] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(44) Project [uid#3005, song_id#3007]\n      :  +- *(44) Filter ((month(date#3010) = 4) && isnotnull(uid#3005))\n      :     +- *(44) FileScan csv [uid#3005,song_id#3007,date#3010] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(45) Project [uid#3023, song_id#3025]\n      :  +- *(45) Filter ((month(date#3028) = 4) && isnotnull(uid#3023))\n      :     +- *(45) FileScan csv [uid#3023,song_id#3025,date#3028] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(46) Project [uid#3041, song_id#3043]\n      :  +- *(46) Filter ((month(date#3046) = 4) && isnotnull(uid#3041))\n      :     +- *(46) FileScan csv [uid#3041,song_id#3043,date#3046] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(47) Project [uid#3059, song_id#3061]\n      :  +- *(47) Filter ((month(date#3064) = 4) && isnotnull(uid#3059))\n      :     +- *(47) FileScan csv [uid#3059,song_id#3061,date#3064] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(48) Project [uid#3077, song_id#3079]\n      :  +- *(48) Filter ((month(date#3082) = 4) && isnotnull(uid#3077))\n      :     +- *(48) FileScan csv [uid#3077,song_id#3079,date#3082] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(49) Project [uid#3095, song_id#3097]\n      :  +- *(49) Filter ((month(date#3100) = 4) && isnotnull(uid#3095))\n      :     +- *(49) FileScan csv [uid#3095,song_id#3097,date#3100] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(50) Project [uid#3113, song_id#3115]\n      :  +- *(50) Filter ((month(date#3118) = 4) && isnotnull(uid#3113))\n      :     +- *(50) FileScan csv [uid#3113,song_id#3115,date#3118] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(51) Project [uid#3131, song_id#3133]\n      :  +- *(51) Filter ((month(date#3136) = 4) && isnotnull(uid#3131))\n      :     +- *(51) FileScan csv [uid#3131,song_id#3133,date#3136] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(52) Project [uid#3149, song_id#3151]\n      :  +- *(52) Filter ((month(date#3154) = 4) && isnotnull(uid#3149))\n      :     +- *(52) FileScan csv [uid#3149,song_id#3151,date#3154] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(53) Project [uid#3167, song_id#3169]\n      :  +- *(53) Filter ((month(date#3172) = 4) && isnotnull(uid#3167))\n      :     +- *(53) FileScan csv [uid#3167,song_id#3169,date#3172] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(54) Project [uid#3185, song_id#3187]\n      :  +- *(54) Filter ((month(date#3190) = 4) && isnotnull(uid#3185))\n      :     +- *(54) FileScan csv [uid#3185,song_id#3187,date#3190] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(55) Project [uid#3203, song_id#3205]\n      :  +- *(55) Filter ((month(date#3208) = 4) && isnotnull(uid#3203))\n      :     +- *(55) FileScan csv [uid#3203,song_id#3205,date#3208] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(56) Project [uid#3221, song_id#3223]\n      :  +- *(56) Filter ((month(date#3226) = 4) && isnotnull(uid#3221))\n      :     +- *(56) FileScan csv [uid#3221,song_id#3223,date#3226] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(57) Project [uid#3239, song_id#3241]\n      :  +- *(57) Filter ((month(date#3244) = 4) && isnotnull(uid#3239))\n      :     +- *(57) FileScan csv [uid#3239,song_id#3241,date#3244] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(58) Project [uid#3257, song_id#3259]\n      :  +- *(58) Filter ((month(date#3262) = 4) && isnotnull(uid#3257))\n      :     +- *(58) FileScan csv [uid#3257,song_id#3259,date#3262] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(59) Project [uid#3275, song_id#3277]\n      :  +- *(59) Filter ((month(date#3280) = 4) && isnotnull(uid#3275))\n      :     +- *(59) FileScan csv [uid#3275,song_id#3277,date#3280] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(60) Project [uid#3293, song_id#3295]\n      :  +- *(60) Filter ((month(date#3298) = 4) && isnotnull(uid#3293))\n      :     +- *(60) FileScan csv [uid#3293,song_id#3295,date#3298] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(61) Project [uid#3311, song_id#3313]\n      :  +- *(61) Filter ((month(date#3316) = 4) && isnotnull(uid#3311))\n      :     +- *(61) FileScan csv [uid#3311,song_id#3313,date#3316] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(62) Project [uid#3329, song_id#3331]\n      :  +- *(62) Filter ((month(date#3334) = 4) && isnotnull(uid#3329))\n      :     +- *(62) FileScan csv [uid#3329,song_id#3331,date#3334] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(63) Project [uid#3347, song_id#3349]\n      :  +- *(63) Filter ((month(date#3352) = 4) && isnotnull(uid#3347))\n      :     +- *(63) FileScan csv [uid#3347,song_id#3349,date#3352] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(64) Project [uid#3365, song_id#3367]\n      :  +- *(64) Filter ((month(date#3370) = 4) && isnotnull(uid#3365))\n      :     +- *(64) FileScan csv [uid#3365,song_id#3367,date#3370] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(65) Project [uid#3383, song_id#3385]\n      :  +- *(65) Filter ((month(date#3388) = 4) && isnotnull(uid#3383))\n      :     +- *(65) FileScan csv [uid#3383,song_id#3385,date#3388] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(66) Project [uid#3401, song_id#3403]\n      :  +- *(66) Filter ((month(date#3406) = 4) && isnotnull(uid#3401))\n      :     +- *(66) FileScan csv [uid#3401,song_id#3403,date#3406] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(67) Project [uid#3419, song_id#3421]\n      :  +- *(67) Filter ((month(date#3424) = 4) && isnotnull(uid#3419))\n      :     +- *(67) FileScan csv [uid#3419,song_id#3421,date#3424] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(68) Project [uid#3437, song_id#3439]\n      :  +- *(68) Filter ((month(date#3442) = 4) && isnotnull(uid#3437))\n      :     +- *(68) FileScan csv [uid#3437,song_id#3439,date#3442] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(69) Project [uid#3455, song_id#3457]\n      :  +- *(69) Filter ((month(date#3460) = 4) && isnotnull(uid#3455))\n      :     +- *(69) FileScan csv [uid#3455,song_id#3457,date#3460] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(70) Project [uid#3473, song_id#3475]\n      :  +- *(70) Filter ((month(date#3478) = 4) && isnotnull(uid#3473))\n      :     +- *(70) FileScan csv [uid#3473,song_id#3475,date#3478] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(71) Project [uid#3491, song_id#3493]\n      :  +- *(71) Filter ((month(date#3496) = 4) && isnotnull(uid#3491))\n      :     +- *(71) FileScan csv [uid#3491,song_id#3493,date#3496] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(72) Project [uid#3509, song_id#3511]\n      :  +- *(72) Filter ((month(date#3514) = 4) && isnotnull(uid#3509))\n      :     +- *(72) FileScan csv [uid#3509,song_id#3511,date#3514] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(73) Project [uid#3527, song_id#3529]\n      :  +- *(73) Filter ((month(date#3532) = 4) && isnotnull(uid#3527))\n      :     +- *(73) FileScan csv [uid#3527,song_id#3529,date#3532] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(74) Project [uid#3545, song_id#3547]\n      :  +- *(74) Filter ((month(date#3550) = 4) && isnotnull(uid#3545))\n      :     +- *(74) FileScan csv [uid#3545,song_id#3547,date#3550] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(75) Project [uid#3563, song_id#3565]\n      :  +- *(75) Filter ((month(date#3568) = 4) && isnotnull(uid#3563))\n      :     +- *(75) FileScan csv [uid#3563,song_id#3565,date#3568] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(76) Project [uid#3581, song_id#3583]\n      :  +- *(76) Filter ((month(date#3586) = 4) && isnotnull(uid#3581))\n      :     +- *(76) FileScan csv [uid#3581,song_id#3583,date#3586] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(77) Project [uid#3599, song_id#3601]\n      :  +- *(77) Filter ((month(date#3604) = 4) && isnotnull(uid#3599))\n      :     +- *(77) FileScan csv [uid#3599,song_id#3601,date#3604] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(78) Project [uid#3617, song_id#3619]\n      :  +- *(78) Filter ((month(date#3622) = 4) && isnotnull(uid#3617))\n      :     +- *(78) FileScan csv [uid#3617,song_id#3619,date#3622] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(79) Project [uid#3635, song_id#3637]\n      :  +- *(79) Filter ((month(date#3640) = 4) && isnotnull(uid#3635))\n      :     +- *(79) FileScan csv [uid#3635,song_id#3637,date#3640] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(80) Project [uid#3653, song_id#3655]\n      :  +- *(80) Filter ((month(date#3658) = 4) && isnotnull(uid#3653))\n      :     +- *(80) FileScan csv [uid#3653,song_id#3655,date#3658] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(81) Project [uid#3671, song_id#3673]\n      :  +- *(81) Filter ((month(date#3676) = 4) && isnotnull(uid#3671))\n      :     +- *(81) FileScan csv [uid#3671,song_id#3673,date#3676] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(82) Project [uid#3689, song_id#3691]\n      :  +- *(82) Filter ((month(date#3694) = 4) && isnotnull(uid#3689))\n      :     +- *(82) FileScan csv [uid#3689,song_id#3691,date#3694] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(83) Project [uid#3707, song_id#3709]\n      :  +- *(83) Filter ((month(date#3712) = 4) && isnotnull(uid#3707))\n      :     +- *(83) FileScan csv [uid#3707,song_id#3709,date#3712] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(84) Project [uid#3725, song_id#3727]\n      :  +- *(84) Filter ((month(date#3730) = 4) && isnotnull(uid#3725))\n      :     +- *(84) FileScan csv [uid#3725,song_id#3727,date#3730] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(85) Project [uid#3743, song_id#3745]\n      :  +- *(85) Filter ((month(date#3748) = 4) && isnotnull(uid#3743))\n      :     +- *(85) FileScan csv [uid#3743,song_id#3745,date#3748] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(86) Project [uid#3761, song_id#3763]\n      :  +- *(86) Filter ((month(date#3766) = 4) && isnotnull(uid#3761))\n      :     +- *(86) FileScan csv [uid#3761,song_id#3763,date#3766] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(87) Project [uid#3779, song_id#3781]\n      :  +- *(87) Filter ((month(date#3784) = 4) && isnotnull(uid#3779))\n      :     +- *(87) FileScan csv [uid#3779,song_id#3781,date#3784] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(88) Project [uid#3797, song_id#3799]\n      :  +- *(88) Filter ((month(date#3802) = 4) && isnotnull(uid#3797))\n      :     +- *(88) FileScan csv [uid#3797,song_id#3799,date#3802] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(89) Project [uid#3815, song_id#3817]\n      :  +- *(89) Filter ((month(date#3820) = 4) && isnotnull(uid#3815))\n      :     +- *(89) FileScan csv [uid#3815,song_id#3817,date#3820] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(90) Project [uid#3833, song_id#3835]\n      :  +- *(90) Filter ((month(date#3838) = 4) && isnotnull(uid#3833))\n      :     +- *(90) FileScan csv [uid#3833,song_id#3835,date#3838] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(91) Project [uid#3851, song_id#3853]\n      :  +- *(91) Filter ((month(date#3856) = 4) && isnotnull(uid#3851))\n      :     +- *(91) FileScan csv [uid#3851,song_id#3853,date#3856] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(92) Project [uid#3869, song_id#3871]\n      :  +- *(92) Filter ((month(date#3874) = 4) && isnotnull(uid#3869))\n      :     +- *(92) FileScan csv [uid#3869,song_id#3871,date#3874] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(93) Project [uid#3887, song_id#3889]\n      :  +- *(93) Filter ((month(date#3892) = 4) && isnotnull(uid#3887))\n      :     +- *(93) FileScan csv [uid#3887,song_id#3889,date#3892] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(94) Project [uid#3905, song_id#3907]\n      :  +- *(94) Filter ((month(date#3910) = 4) && isnotnull(uid#3905))\n      :     +- *(94) FileScan csv [uid#3905,song_id#3907,date#3910] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(95) Project [uid#3923, song_id#3925]\n      :  +- *(95) Filter ((month(date#3928) = 4) && isnotnull(uid#3923))\n      :     +- *(95) FileScan csv [uid#3923,song_id#3925,date#3928] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(96) Project [uid#3941, song_id#3943]\n      :  +- *(96) Filter ((month(date#3946) = 4) && isnotnull(uid#3941))\n      :     +- *(96) FileScan csv [uid#3941,song_id#3943,date#3946] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(97) Project [uid#3959, song_id#3961]\n      :  +- *(97) Filter ((month(date#3964) = 4) && isnotnull(uid#3959))\n      :     +- *(97) FileScan csv [uid#3959,song_id#3961,date#3964] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(98) Project [uid#3977, song_id#3979]\n      :  +- *(98) Filter ((month(date#3982) = 4) && isnotnull(uid#3977))\n      :     +- *(98) FileScan csv [uid#3977,song_id#3979,date#3982] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(99) Project [uid#3995, song_id#3997]\n      :  +- *(99) Filter ((month(date#4000) = 4) && isnotnull(uid#3995))\n      :     +- *(99) FileScan csv [uid#3995,song_id#3997,date#4000] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(100) Project [uid#4013, song_id#4015]\n      :  +- *(100) Filter ((month(date#4018) = 4) && isnotnull(uid#4013))\n      :     +- *(100) FileScan csv [uid#4013,song_id#4015,date#4018] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(101) Project [uid#4031, song_id#4033]\n      :  +- *(101) Filter ((month(date#4036) = 4) && isnotnull(uid#4031))\n      :     +- *(101) FileScan csv [uid#4031,song_id#4033,date#4036] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(102) Project [uid#4049, song_id#4051]\n      :  +- *(102) Filter ((month(date#4054) = 4) && isnotnull(uid#4049))\n      :     +- *(102) FileScan csv [uid#4049,song_id#4051,date#4054] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(103) Project [uid#4067, song_id#4069]\n      :  +- *(103) Filter ((month(date#4072) = 4) && isnotnull(uid#4067))\n      :     +- *(103) FileScan csv [uid#4067,song_id#4069,date#4072] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(104) Project [uid#4085, song_id#4087]\n      :  +- *(104) Filter ((month(date#4090) = 4) && isnotnull(uid#4085))\n      :     +- *(104) FileScan csv [uid#4085,song_id#4087,date#4090] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(105) Project [uid#4103, song_id#4105]\n      :  +- *(105) Filter ((month(date#4108) = 4) && isnotnull(uid#4103))\n      :     +- *(105) FileScan csv [uid#4103,song_id#4105,date#4108] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(106) Project [uid#4121, song_id#4123]\n      :  +- *(106) Filter ((month(date#4126) = 4) && isnotnull(uid#4121))\n      :     +- *(106) FileScan csv [uid#4121,song_id#4123,date#4126] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(107) Project [uid#4139, song_id#4141]\n      :  +- *(107) Filter ((month(date#4144) = 4) && isnotnull(uid#4139))\n      :     +- *(107) FileScan csv [uid#4139,song_id#4141,date#4144] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(108) Project [uid#4157, song_id#4159]\n      :  +- *(108) Filter ((month(date#4162) = 4) && isnotnull(uid#4157))\n      :     +- *(108) FileScan csv [uid#4157,song_id#4159,date#4162] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(109) Project [uid#4175, song_id#4177]\n      :  +- *(109) Filter ((month(date#4180) = 4) && isnotnull(uid#4175))\n      :     +- *(109) FileScan csv [uid#4175,song_id#4177,date#4180] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(110) Project [uid#4193, song_id#4195]\n      :  +- *(110) Filter ((month(date#4198) = 4) && isnotnull(uid#4193))\n      :     +- *(110) FileScan csv [uid#4193,song_id#4195,date#4198] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(111) Project [uid#4211, song_id#4213]\n      :  +- *(111) Filter ((month(date#4216) = 4) && isnotnull(uid#4211))\n      :     +- *(111) FileScan csv [uid#4211,song_id#4213,date#4216] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(112) Project [uid#4229, song_id#4231]\n      :  +- *(112) Filter ((month(date#4234) = 4) && isnotnull(uid#4229))\n      :     +- *(112) FileScan csv [uid#4229,song_id#4231,date#4234] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(113) Project [uid#4247, song_id#4249]\n      :  +- *(113) Filter ((month(date#4252) = 4) && isnotnull(uid#4247))\n      :     +- *(113) FileScan csv [uid#4247,song_id#4249,date#4252] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(114) Project [uid#4265, song_id#4267]\n      :  +- *(114) Filter ((month(date#4270) = 4) && isnotnull(uid#4265))\n      :     +- *(114) FileScan csv [uid#4265,song_id#4267,date#4270] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(115) Project [uid#4283, song_id#4285]\n      :  +- *(115) Filter ((month(date#4288) = 4) && isnotnull(uid#4283))\n      :     +- *(115) FileScan csv [uid#4283,song_id#4285,date#4288] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(116) Project [uid#4301, song_id#4303]\n      :  +- *(116) Filter ((month(date#4306) = 4) && isnotnull(uid#4301))\n      :     +- *(116) FileScan csv [uid#4301,song_id#4303,date#4306] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(117) Project [uid#4319, song_id#4321]\n      :  +- *(117) Filter ((month(date#4324) = 4) && isnotnull(uid#4319))\n      :     +- *(117) FileScan csv [uid#4319,song_id#4321,date#4324] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(118) Project [uid#4337, song_id#4339]\n      :  +- *(118) Filter ((month(date#4342) = 4) && isnotnull(uid#4337))\n      :     +- *(118) FileScan csv [uid#4337,song_id#4339,date#4342] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(119) Project [uid#4355, song_id#4357]\n      :  +- *(119) Filter ((month(date#4360) = 4) && isnotnull(uid#4355))\n      :     +- *(119) FileScan csv [uid#4355,song_id#4357,date#4360] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(120) Project [uid#4373, song_id#4375]\n      :  +- *(120) Filter ((month(date#4378) = 4) && isnotnull(uid#4373))\n      :     +- *(120) FileScan csv [uid#4373,song_id#4375,date#4378] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(121) Project [uid#4391, song_id#4393]\n      :  +- *(121) Filter ((month(date#4396) = 4) && isnotnull(uid#4391))\n      :     +- *(121) FileScan csv [uid#4391,song_id#4393,date#4396] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(122) Project [uid#4409, song_id#4411]\n      :  +- *(122) Filter ((month(date#4414) = 4) && isnotnull(uid#4409))\n      :     +- *(122) FileScan csv [uid#4409,song_id#4411,date#4414] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(123) Project [uid#4427, song_id#4429]\n      :  +- *(123) Filter ((month(date#4432) = 4) && isnotnull(uid#4427))\n      :     +- *(123) FileScan csv [uid#4427,song_id#4429,date#4432] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      +- *(124) Project [uid#4445, song_id#4447]\n         +- *(124) Filter ((month(date#4450) = 4) && isnotnull(uid#4445))\n            +- *(124) FileScan csv [uid#4445,song_id#4447,date#4450] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:56)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:371)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:150)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecute(WholeStageCodegenExec.scala:363)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.inputRDDs(SortMergeJoinExec.scala:386)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecute(WholeStageCodegenExec.scala:363)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.inputRDDs(SortMergeJoinExec.scala:386)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecute(WholeStageCodegenExec.scala:363)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.inputRDDs(SortMergeJoinExec.scala:386)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecute(WholeStageCodegenExec.scala:363)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.inputRDDs(SortMergeJoinExec.scala:386)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecute(WholeStageCodegenExec.scala:363)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.inputRDDs(SortMergeJoinExec.scala:386)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.UnionExec$$anonfun$doExecute$1.apply(basicPhysicalOperators.scala:557)\n\tat org.apache.spark.sql.execution.UnionExec$$anonfun$doExecute$1.apply(basicPhysicalOperators.scala:557)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.foreach(List.scala:381)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.map(List.scala:285)\n\tat org.apache.spark.sql.execution.UnionExec.doExecute(basicPhysicalOperators.scala:557)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:371)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.SampleExec.inputRDDs(basicPhysicalOperators.scala:271)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.BaseLimitExec$class.inputRDDs(limit.scala:62)\n\tat org.apache.spark.sql.execution.LocalLimitExec.inputRDDs(limit.scala:97)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:247)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:337)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3272)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3253)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3252)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2698)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:254)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\nThis stopped SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\nsun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\nsun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\nsun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.lang.reflect.Constructor.newInstance(Constructor.java:423)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.GatewayConnection.run(GatewayConnection.java:214)\njava.lang.Thread.run(Thread.java:748)\n\nThe currently active SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\nsun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\nsun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\nsun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.lang.reflect.Constructor.newInstance(Constructor.java:423)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.GatewayConnection.run(GatewayConnection.java:214)\njava.lang.Thread.run(Thread.java:748)\n         \n\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:99)\n\tat org.apache.spark.SparkContext.broadcast(SparkContext.scala:1478)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:96)\n\tat org.apache.spark.sql.execution.datasources.FileFormat$class.buildReaderWithPartitionValues(FileFormat.scala:129)\n\tat org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:160)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:295)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:293)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDDs(DataSourceScanExec.scala:313)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:121)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.UnionExec$$anonfun$doExecute$1.apply(basicPhysicalOperators.scala:557)\n\tat org.apache.spark.sql.execution.UnionExec$$anonfun$doExecute$1.apply(basicPhysicalOperators.scala:557)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.execution.UnionExec.doExecute(basicPhysicalOperators.scala:557)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:371)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:150)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\t... 149 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-f873bb6aa2a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \"\"\"\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1160\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    319\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o5116.showString.\n: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:\nExchange hashpartitioning(uid#2237, 200)\n+- *(125) HashAggregate(keys=[uid#2237], functions=[partial_count(song_id#2239)], output=[uid#2237, count#22433L])\n   +- Union\n      :- *(1) Project [uid#2237, song_id#2239]\n      :  +- *(1) Filter ((month(date#2242) = 4) && isnotnull(uid#2237))\n      :     +- *(1) FileScan csv [uid#2237,song_id#2239,date#2242] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(2) Project [uid#2249, song_id#2251]\n      :  +- *(2) Filter ((month(date#2254) = 4) && isnotnull(uid#2249))\n      :     +- *(2) FileScan csv [uid#2249,song_id#2251,date#2254] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(3) Project [uid#2267, song_id#2269]\n      :  +- *(3) Filter ((month(date#2272) = 4) && isnotnull(uid#2267))\n      :     +- *(3) FileScan csv [uid#2267,song_id#2269,date#2272] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(4) Project [uid#2285, song_id#2287]\n      :  +- *(4) Filter ((month(date#2290) = 4) && isnotnull(uid#2285))\n      :     +- *(4) FileScan csv [uid#2285,song_id#2287,date#2290] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(5) Project [uid#2303, song_id#2305]\n      :  +- *(5) Filter ((month(date#2308) = 4) && isnotnull(uid#2303))\n      :     +- *(5) FileScan csv [uid#2303,song_id#2305,date#2308] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(6) Project [uid#2321, song_id#2323]\n      :  +- *(6) Filter ((month(date#2326) = 4) && isnotnull(uid#2321))\n      :     +- *(6) FileScan csv [uid#2321,song_id#2323,date#2326] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(7) Project [uid#2339, song_id#2341]\n      :  +- *(7) Filter ((month(date#2344) = 4) && isnotnull(uid#2339))\n      :     +- *(7) FileScan csv [uid#2339,song_id#2341,date#2344] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(8) Project [uid#2357, song_id#2359]\n      :  +- *(8) Filter ((month(date#2362) = 4) && isnotnull(uid#2357))\n      :     +- *(8) FileScan csv [uid#2357,song_id#2359,date#2362] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(9) Project [uid#2375, song_id#2377]\n      :  +- *(9) Filter ((month(date#2380) = 4) && isnotnull(uid#2375))\n      :     +- *(9) FileScan csv [uid#2375,song_id#2377,date#2380] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(10) Project [uid#2393, song_id#2395]\n      :  +- *(10) Filter ((month(date#2398) = 4) && isnotnull(uid#2393))\n      :     +- *(10) FileScan csv [uid#2393,song_id#2395,date#2398] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(11) Project [uid#2411, song_id#2413]\n      :  +- *(11) Filter ((month(date#2416) = 4) && isnotnull(uid#2411))\n      :     +- *(11) FileScan csv [uid#2411,song_id#2413,date#2416] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(12) Project [uid#2429, song_id#2431]\n      :  +- *(12) Filter ((month(date#2434) = 4) && isnotnull(uid#2429))\n      :     +- *(12) FileScan csv [uid#2429,song_id#2431,date#2434] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(13) Project [uid#2447, song_id#2449]\n      :  +- *(13) Filter ((month(date#2452) = 4) && isnotnull(uid#2447))\n      :     +- *(13) FileScan csv [uid#2447,song_id#2449,date#2452] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(14) Project [uid#2465, song_id#2467]\n      :  +- *(14) Filter ((month(date#2470) = 4) && isnotnull(uid#2465))\n      :     +- *(14) FileScan csv [uid#2465,song_id#2467,date#2470] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(15) Project [uid#2483, song_id#2485]\n      :  +- *(15) Filter ((month(date#2488) = 4) && isnotnull(uid#2483))\n      :     +- *(15) FileScan csv [uid#2483,song_id#2485,date#2488] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(16) Project [uid#2501, song_id#2503]\n      :  +- *(16) Filter ((month(date#2506) = 4) && isnotnull(uid#2501))\n      :     +- *(16) FileScan csv [uid#2501,song_id#2503,date#2506] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(17) Project [uid#2519, song_id#2521]\n      :  +- *(17) Filter ((month(date#2524) = 4) && isnotnull(uid#2519))\n      :     +- *(17) FileScan csv [uid#2519,song_id#2521,date#2524] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(18) Project [uid#2537, song_id#2539]\n      :  +- *(18) Filter ((month(date#2542) = 4) && isnotnull(uid#2537))\n      :     +- *(18) FileScan csv [uid#2537,song_id#2539,date#2542] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(19) Project [uid#2555, song_id#2557]\n      :  +- *(19) Filter ((month(date#2560) = 4) && isnotnull(uid#2555))\n      :     +- *(19) FileScan csv [uid#2555,song_id#2557,date#2560] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(20) Project [uid#2573, song_id#2575]\n      :  +- *(20) Filter ((month(date#2578) = 4) && isnotnull(uid#2573))\n      :     +- *(20) FileScan csv [uid#2573,song_id#2575,date#2578] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(21) Project [uid#2591, song_id#2593]\n      :  +- *(21) Filter ((month(date#2596) = 4) && isnotnull(uid#2591))\n      :     +- *(21) FileScan csv [uid#2591,song_id#2593,date#2596] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(22) Project [uid#2609, song_id#2611]\n      :  +- *(22) Filter ((month(date#2614) = 4) && isnotnull(uid#2609))\n      :     +- *(22) FileScan csv [uid#2609,song_id#2611,date#2614] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(23) Project [uid#2627, song_id#2629]\n      :  +- *(23) Filter ((month(date#2632) = 4) && isnotnull(uid#2627))\n      :     +- *(23) FileScan csv [uid#2627,song_id#2629,date#2632] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(24) Project [uid#2645, song_id#2647]\n      :  +- *(24) Filter ((month(date#2650) = 4) && isnotnull(uid#2645))\n      :     +- *(24) FileScan csv [uid#2645,song_id#2647,date#2650] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(25) Project [uid#2663, song_id#2665]\n      :  +- *(25) Filter ((month(date#2668) = 4) && isnotnull(uid#2663))\n      :     +- *(25) FileScan csv [uid#2663,song_id#2665,date#2668] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(26) Project [uid#2681, song_id#2683]\n      :  +- *(26) Filter ((month(date#2686) = 4) && isnotnull(uid#2681))\n      :     +- *(26) FileScan csv [uid#2681,song_id#2683,date#2686] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(27) Project [uid#2699, song_id#2701]\n      :  +- *(27) Filter ((month(date#2704) = 4) && isnotnull(uid#2699))\n      :     +- *(27) FileScan csv [uid#2699,song_id#2701,date#2704] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(28) Project [uid#2717, song_id#2719]\n      :  +- *(28) Filter ((month(date#2722) = 4) && isnotnull(uid#2717))\n      :     +- *(28) FileScan csv [uid#2717,song_id#2719,date#2722] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(29) Project [uid#2735, song_id#2737]\n      :  +- *(29) Filter ((month(date#2740) = 4) && isnotnull(uid#2735))\n      :     +- *(29) FileScan csv [uid#2735,song_id#2737,date#2740] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(30) Project [uid#2753, song_id#2755]\n      :  +- *(30) Filter ((month(date#2758) = 4) && isnotnull(uid#2753))\n      :     +- *(30) FileScan csv [uid#2753,song_id#2755,date#2758] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(31) Project [uid#2771, song_id#2773]\n      :  +- *(31) Filter ((month(date#2776) = 4) && isnotnull(uid#2771))\n      :     +- *(31) FileScan csv [uid#2771,song_id#2773,date#2776] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(32) Project [uid#2789, song_id#2791]\n      :  +- *(32) Filter ((month(date#2794) = 4) && isnotnull(uid#2789))\n      :     +- *(32) FileScan csv [uid#2789,song_id#2791,date#2794] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(33) Project [uid#2807, song_id#2809]\n      :  +- *(33) Filter ((month(date#2812) = 4) && isnotnull(uid#2807))\n      :     +- *(33) FileScan csv [uid#2807,song_id#2809,date#2812] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(34) Project [uid#2825, song_id#2827]\n      :  +- *(34) Filter ((month(date#2830) = 4) && isnotnull(uid#2825))\n      :     +- *(34) FileScan csv [uid#2825,song_id#2827,date#2830] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(35) Project [uid#2843, song_id#2845]\n      :  +- *(35) Filter ((month(date#2848) = 4) && isnotnull(uid#2843))\n      :     +- *(35) FileScan csv [uid#2843,song_id#2845,date#2848] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(36) Project [uid#2861, song_id#2863]\n      :  +- *(36) Filter ((month(date#2866) = 4) && isnotnull(uid#2861))\n      :     +- *(36) FileScan csv [uid#2861,song_id#2863,date#2866] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(37) Project [uid#2879, song_id#2881]\n      :  +- *(37) Filter ((month(date#2884) = 4) && isnotnull(uid#2879))\n      :     +- *(37) FileScan csv [uid#2879,song_id#2881,date#2884] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(38) Project [uid#2897, song_id#2899]\n      :  +- *(38) Filter ((month(date#2902) = 4) && isnotnull(uid#2897))\n      :     +- *(38) FileScan csv [uid#2897,song_id#2899,date#2902] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(39) Project [uid#2915, song_id#2917]\n      :  +- *(39) Filter ((month(date#2920) = 4) && isnotnull(uid#2915))\n      :     +- *(39) FileScan csv [uid#2915,song_id#2917,date#2920] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(40) Project [uid#2933, song_id#2935]\n      :  +- *(40) Filter ((month(date#2938) = 4) && isnotnull(uid#2933))\n      :     +- *(40) FileScan csv [uid#2933,song_id#2935,date#2938] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(41) Project [uid#2951, song_id#2953]\n      :  +- *(41) Filter ((month(date#2956) = 4) && isnotnull(uid#2951))\n      :     +- *(41) FileScan csv [uid#2951,song_id#2953,date#2956] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(42) Project [uid#2969, song_id#2971]\n      :  +- *(42) Filter ((month(date#2974) = 4) && isnotnull(uid#2969))\n      :     +- *(42) FileScan csv [uid#2969,song_id#2971,date#2974] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(43) Project [uid#2987, song_id#2989]\n      :  +- *(43) Filter ((month(date#2992) = 4) && isnotnull(uid#2987))\n      :     +- *(43) FileScan csv [uid#2987,song_id#2989,date#2992] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(44) Project [uid#3005, song_id#3007]\n      :  +- *(44) Filter ((month(date#3010) = 4) && isnotnull(uid#3005))\n      :     +- *(44) FileScan csv [uid#3005,song_id#3007,date#3010] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(45) Project [uid#3023, song_id#3025]\n      :  +- *(45) Filter ((month(date#3028) = 4) && isnotnull(uid#3023))\n      :     +- *(45) FileScan csv [uid#3023,song_id#3025,date#3028] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(46) Project [uid#3041, song_id#3043]\n      :  +- *(46) Filter ((month(date#3046) = 4) && isnotnull(uid#3041))\n      :     +- *(46) FileScan csv [uid#3041,song_id#3043,date#3046] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(47) Project [uid#3059, song_id#3061]\n      :  +- *(47) Filter ((month(date#3064) = 4) && isnotnull(uid#3059))\n      :     +- *(47) FileScan csv [uid#3059,song_id#3061,date#3064] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(48) Project [uid#3077, song_id#3079]\n      :  +- *(48) Filter ((month(date#3082) = 4) && isnotnull(uid#3077))\n      :     +- *(48) FileScan csv [uid#3077,song_id#3079,date#3082] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(49) Project [uid#3095, song_id#3097]\n      :  +- *(49) Filter ((month(date#3100) = 4) && isnotnull(uid#3095))\n      :     +- *(49) FileScan csv [uid#3095,song_id#3097,date#3100] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(50) Project [uid#3113, song_id#3115]\n      :  +- *(50) Filter ((month(date#3118) = 4) && isnotnull(uid#3113))\n      :     +- *(50) FileScan csv [uid#3113,song_id#3115,date#3118] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(51) Project [uid#3131, song_id#3133]\n      :  +- *(51) Filter ((month(date#3136) = 4) && isnotnull(uid#3131))\n      :     +- *(51) FileScan csv [uid#3131,song_id#3133,date#3136] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(52) Project [uid#3149, song_id#3151]\n      :  +- *(52) Filter ((month(date#3154) = 4) && isnotnull(uid#3149))\n      :     +- *(52) FileScan csv [uid#3149,song_id#3151,date#3154] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(53) Project [uid#3167, song_id#3169]\n      :  +- *(53) Filter ((month(date#3172) = 4) && isnotnull(uid#3167))\n      :     +- *(53) FileScan csv [uid#3167,song_id#3169,date#3172] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(54) Project [uid#3185, song_id#3187]\n      :  +- *(54) Filter ((month(date#3190) = 4) && isnotnull(uid#3185))\n      :     +- *(54) FileScan csv [uid#3185,song_id#3187,date#3190] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(55) Project [uid#3203, song_id#3205]\n      :  +- *(55) Filter ((month(date#3208) = 4) && isnotnull(uid#3203))\n      :     +- *(55) FileScan csv [uid#3203,song_id#3205,date#3208] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(56) Project [uid#3221, song_id#3223]\n      :  +- *(56) Filter ((month(date#3226) = 4) && isnotnull(uid#3221))\n      :     +- *(56) FileScan csv [uid#3221,song_id#3223,date#3226] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(57) Project [uid#3239, song_id#3241]\n      :  +- *(57) Filter ((month(date#3244) = 4) && isnotnull(uid#3239))\n      :     +- *(57) FileScan csv [uid#3239,song_id#3241,date#3244] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(58) Project [uid#3257, song_id#3259]\n      :  +- *(58) Filter ((month(date#3262) = 4) && isnotnull(uid#3257))\n      :     +- *(58) FileScan csv [uid#3257,song_id#3259,date#3262] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(59) Project [uid#3275, song_id#3277]\n      :  +- *(59) Filter ((month(date#3280) = 4) && isnotnull(uid#3275))\n      :     +- *(59) FileScan csv [uid#3275,song_id#3277,date#3280] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(60) Project [uid#3293, song_id#3295]\n      :  +- *(60) Filter ((month(date#3298) = 4) && isnotnull(uid#3293))\n      :     +- *(60) FileScan csv [uid#3293,song_id#3295,date#3298] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(61) Project [uid#3311, song_id#3313]\n      :  +- *(61) Filter ((month(date#3316) = 4) && isnotnull(uid#3311))\n      :     +- *(61) FileScan csv [uid#3311,song_id#3313,date#3316] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(62) Project [uid#3329, song_id#3331]\n      :  +- *(62) Filter ((month(date#3334) = 4) && isnotnull(uid#3329))\n      :     +- *(62) FileScan csv [uid#3329,song_id#3331,date#3334] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(63) Project [uid#3347, song_id#3349]\n      :  +- *(63) Filter ((month(date#3352) = 4) && isnotnull(uid#3347))\n      :     +- *(63) FileScan csv [uid#3347,song_id#3349,date#3352] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(64) Project [uid#3365, song_id#3367]\n      :  +- *(64) Filter ((month(date#3370) = 4) && isnotnull(uid#3365))\n      :     +- *(64) FileScan csv [uid#3365,song_id#3367,date#3370] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(65) Project [uid#3383, song_id#3385]\n      :  +- *(65) Filter ((month(date#3388) = 4) && isnotnull(uid#3383))\n      :     +- *(65) FileScan csv [uid#3383,song_id#3385,date#3388] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(66) Project [uid#3401, song_id#3403]\n      :  +- *(66) Filter ((month(date#3406) = 4) && isnotnull(uid#3401))\n      :     +- *(66) FileScan csv [uid#3401,song_id#3403,date#3406] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(67) Project [uid#3419, song_id#3421]\n      :  +- *(67) Filter ((month(date#3424) = 4) && isnotnull(uid#3419))\n      :     +- *(67) FileScan csv [uid#3419,song_id#3421,date#3424] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(68) Project [uid#3437, song_id#3439]\n      :  +- *(68) Filter ((month(date#3442) = 4) && isnotnull(uid#3437))\n      :     +- *(68) FileScan csv [uid#3437,song_id#3439,date#3442] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(69) Project [uid#3455, song_id#3457]\n      :  +- *(69) Filter ((month(date#3460) = 4) && isnotnull(uid#3455))\n      :     +- *(69) FileScan csv [uid#3455,song_id#3457,date#3460] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(70) Project [uid#3473, song_id#3475]\n      :  +- *(70) Filter ((month(date#3478) = 4) && isnotnull(uid#3473))\n      :     +- *(70) FileScan csv [uid#3473,song_id#3475,date#3478] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(71) Project [uid#3491, song_id#3493]\n      :  +- *(71) Filter ((month(date#3496) = 4) && isnotnull(uid#3491))\n      :     +- *(71) FileScan csv [uid#3491,song_id#3493,date#3496] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(72) Project [uid#3509, song_id#3511]\n      :  +- *(72) Filter ((month(date#3514) = 4) && isnotnull(uid#3509))\n      :     +- *(72) FileScan csv [uid#3509,song_id#3511,date#3514] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(73) Project [uid#3527, song_id#3529]\n      :  +- *(73) Filter ((month(date#3532) = 4) && isnotnull(uid#3527))\n      :     +- *(73) FileScan csv [uid#3527,song_id#3529,date#3532] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(74) Project [uid#3545, song_id#3547]\n      :  +- *(74) Filter ((month(date#3550) = 4) && isnotnull(uid#3545))\n      :     +- *(74) FileScan csv [uid#3545,song_id#3547,date#3550] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(75) Project [uid#3563, song_id#3565]\n      :  +- *(75) Filter ((month(date#3568) = 4) && isnotnull(uid#3563))\n      :     +- *(75) FileScan csv [uid#3563,song_id#3565,date#3568] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(76) Project [uid#3581, song_id#3583]\n      :  +- *(76) Filter ((month(date#3586) = 4) && isnotnull(uid#3581))\n      :     +- *(76) FileScan csv [uid#3581,song_id#3583,date#3586] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(77) Project [uid#3599, song_id#3601]\n      :  +- *(77) Filter ((month(date#3604) = 4) && isnotnull(uid#3599))\n      :     +- *(77) FileScan csv [uid#3599,song_id#3601,date#3604] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(78) Project [uid#3617, song_id#3619]\n      :  +- *(78) Filter ((month(date#3622) = 4) && isnotnull(uid#3617))\n      :     +- *(78) FileScan csv [uid#3617,song_id#3619,date#3622] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(79) Project [uid#3635, song_id#3637]\n      :  +- *(79) Filter ((month(date#3640) = 4) && isnotnull(uid#3635))\n      :     +- *(79) FileScan csv [uid#3635,song_id#3637,date#3640] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(80) Project [uid#3653, song_id#3655]\n      :  +- *(80) Filter ((month(date#3658) = 4) && isnotnull(uid#3653))\n      :     +- *(80) FileScan csv [uid#3653,song_id#3655,date#3658] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(81) Project [uid#3671, song_id#3673]\n      :  +- *(81) Filter ((month(date#3676) = 4) && isnotnull(uid#3671))\n      :     +- *(81) FileScan csv [uid#3671,song_id#3673,date#3676] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(82) Project [uid#3689, song_id#3691]\n      :  +- *(82) Filter ((month(date#3694) = 4) && isnotnull(uid#3689))\n      :     +- *(82) FileScan csv [uid#3689,song_id#3691,date#3694] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(83) Project [uid#3707, song_id#3709]\n      :  +- *(83) Filter ((month(date#3712) = 4) && isnotnull(uid#3707))\n      :     +- *(83) FileScan csv [uid#3707,song_id#3709,date#3712] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(84) Project [uid#3725, song_id#3727]\n      :  +- *(84) Filter ((month(date#3730) = 4) && isnotnull(uid#3725))\n      :     +- *(84) FileScan csv [uid#3725,song_id#3727,date#3730] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(85) Project [uid#3743, song_id#3745]\n      :  +- *(85) Filter ((month(date#3748) = 4) && isnotnull(uid#3743))\n      :     +- *(85) FileScan csv [uid#3743,song_id#3745,date#3748] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(86) Project [uid#3761, song_id#3763]\n      :  +- *(86) Filter ((month(date#3766) = 4) && isnotnull(uid#3761))\n      :     +- *(86) FileScan csv [uid#3761,song_id#3763,date#3766] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(87) Project [uid#3779, song_id#3781]\n      :  +- *(87) Filter ((month(date#3784) = 4) && isnotnull(uid#3779))\n      :     +- *(87) FileScan csv [uid#3779,song_id#3781,date#3784] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(88) Project [uid#3797, song_id#3799]\n      :  +- *(88) Filter ((month(date#3802) = 4) && isnotnull(uid#3797))\n      :     +- *(88) FileScan csv [uid#3797,song_id#3799,date#3802] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(89) Project [uid#3815, song_id#3817]\n      :  +- *(89) Filter ((month(date#3820) = 4) && isnotnull(uid#3815))\n      :     +- *(89) FileScan csv [uid#3815,song_id#3817,date#3820] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(90) Project [uid#3833, song_id#3835]\n      :  +- *(90) Filter ((month(date#3838) = 4) && isnotnull(uid#3833))\n      :     +- *(90) FileScan csv [uid#3833,song_id#3835,date#3838] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(91) Project [uid#3851, song_id#3853]\n      :  +- *(91) Filter ((month(date#3856) = 4) && isnotnull(uid#3851))\n      :     +- *(91) FileScan csv [uid#3851,song_id#3853,date#3856] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(92) Project [uid#3869, song_id#3871]\n      :  +- *(92) Filter ((month(date#3874) = 4) && isnotnull(uid#3869))\n      :     +- *(92) FileScan csv [uid#3869,song_id#3871,date#3874] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(93) Project [uid#3887, song_id#3889]\n      :  +- *(93) Filter ((month(date#3892) = 4) && isnotnull(uid#3887))\n      :     +- *(93) FileScan csv [uid#3887,song_id#3889,date#3892] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(94) Project [uid#3905, song_id#3907]\n      :  +- *(94) Filter ((month(date#3910) = 4) && isnotnull(uid#3905))\n      :     +- *(94) FileScan csv [uid#3905,song_id#3907,date#3910] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(95) Project [uid#3923, song_id#3925]\n      :  +- *(95) Filter ((month(date#3928) = 4) && isnotnull(uid#3923))\n      :     +- *(95) FileScan csv [uid#3923,song_id#3925,date#3928] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(96) Project [uid#3941, song_id#3943]\n      :  +- *(96) Filter ((month(date#3946) = 4) && isnotnull(uid#3941))\n      :     +- *(96) FileScan csv [uid#3941,song_id#3943,date#3946] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(97) Project [uid#3959, song_id#3961]\n      :  +- *(97) Filter ((month(date#3964) = 4) && isnotnull(uid#3959))\n      :     +- *(97) FileScan csv [uid#3959,song_id#3961,date#3964] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(98) Project [uid#3977, song_id#3979]\n      :  +- *(98) Filter ((month(date#3982) = 4) && isnotnull(uid#3977))\n      :     +- *(98) FileScan csv [uid#3977,song_id#3979,date#3982] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(99) Project [uid#3995, song_id#3997]\n      :  +- *(99) Filter ((month(date#4000) = 4) && isnotnull(uid#3995))\n      :     +- *(99) FileScan csv [uid#3995,song_id#3997,date#4000] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(100) Project [uid#4013, song_id#4015]\n      :  +- *(100) Filter ((month(date#4018) = 4) && isnotnull(uid#4013))\n      :     +- *(100) FileScan csv [uid#4013,song_id#4015,date#4018] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(101) Project [uid#4031, song_id#4033]\n      :  +- *(101) Filter ((month(date#4036) = 4) && isnotnull(uid#4031))\n      :     +- *(101) FileScan csv [uid#4031,song_id#4033,date#4036] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(102) Project [uid#4049, song_id#4051]\n      :  +- *(102) Filter ((month(date#4054) = 4) && isnotnull(uid#4049))\n      :     +- *(102) FileScan csv [uid#4049,song_id#4051,date#4054] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(103) Project [uid#4067, song_id#4069]\n      :  +- *(103) Filter ((month(date#4072) = 4) && isnotnull(uid#4067))\n      :     +- *(103) FileScan csv [uid#4067,song_id#4069,date#4072] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(104) Project [uid#4085, song_id#4087]\n      :  +- *(104) Filter ((month(date#4090) = 4) && isnotnull(uid#4085))\n      :     +- *(104) FileScan csv [uid#4085,song_id#4087,date#4090] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(105) Project [uid#4103, song_id#4105]\n      :  +- *(105) Filter ((month(date#4108) = 4) && isnotnull(uid#4103))\n      :     +- *(105) FileScan csv [uid#4103,song_id#4105,date#4108] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(106) Project [uid#4121, song_id#4123]\n      :  +- *(106) Filter ((month(date#4126) = 4) && isnotnull(uid#4121))\n      :     +- *(106) FileScan csv [uid#4121,song_id#4123,date#4126] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(107) Project [uid#4139, song_id#4141]\n      :  +- *(107) Filter ((month(date#4144) = 4) && isnotnull(uid#4139))\n      :     +- *(107) FileScan csv [uid#4139,song_id#4141,date#4144] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(108) Project [uid#4157, song_id#4159]\n      :  +- *(108) Filter ((month(date#4162) = 4) && isnotnull(uid#4157))\n      :     +- *(108) FileScan csv [uid#4157,song_id#4159,date#4162] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(109) Project [uid#4175, song_id#4177]\n      :  +- *(109) Filter ((month(date#4180) = 4) && isnotnull(uid#4175))\n      :     +- *(109) FileScan csv [uid#4175,song_id#4177,date#4180] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(110) Project [uid#4193, song_id#4195]\n      :  +- *(110) Filter ((month(date#4198) = 4) && isnotnull(uid#4193))\n      :     +- *(110) FileScan csv [uid#4193,song_id#4195,date#4198] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(111) Project [uid#4211, song_id#4213]\n      :  +- *(111) Filter ((month(date#4216) = 4) && isnotnull(uid#4211))\n      :     +- *(111) FileScan csv [uid#4211,song_id#4213,date#4216] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(112) Project [uid#4229, song_id#4231]\n      :  +- *(112) Filter ((month(date#4234) = 4) && isnotnull(uid#4229))\n      :     +- *(112) FileScan csv [uid#4229,song_id#4231,date#4234] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(113) Project [uid#4247, song_id#4249]\n      :  +- *(113) Filter ((month(date#4252) = 4) && isnotnull(uid#4247))\n      :     +- *(113) FileScan csv [uid#4247,song_id#4249,date#4252] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(114) Project [uid#4265, song_id#4267]\n      :  +- *(114) Filter ((month(date#4270) = 4) && isnotnull(uid#4265))\n      :     +- *(114) FileScan csv [uid#4265,song_id#4267,date#4270] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(115) Project [uid#4283, song_id#4285]\n      :  +- *(115) Filter ((month(date#4288) = 4) && isnotnull(uid#4283))\n      :     +- *(115) FileScan csv [uid#4283,song_id#4285,date#4288] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(116) Project [uid#4301, song_id#4303]\n      :  +- *(116) Filter ((month(date#4306) = 4) && isnotnull(uid#4301))\n      :     +- *(116) FileScan csv [uid#4301,song_id#4303,date#4306] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(117) Project [uid#4319, song_id#4321]\n      :  +- *(117) Filter ((month(date#4324) = 4) && isnotnull(uid#4319))\n      :     +- *(117) FileScan csv [uid#4319,song_id#4321,date#4324] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(118) Project [uid#4337, song_id#4339]\n      :  +- *(118) Filter ((month(date#4342) = 4) && isnotnull(uid#4337))\n      :     +- *(118) FileScan csv [uid#4337,song_id#4339,date#4342] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(119) Project [uid#4355, song_id#4357]\n      :  +- *(119) Filter ((month(date#4360) = 4) && isnotnull(uid#4355))\n      :     +- *(119) FileScan csv [uid#4355,song_id#4357,date#4360] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(120) Project [uid#4373, song_id#4375]\n      :  +- *(120) Filter ((month(date#4378) = 4) && isnotnull(uid#4373))\n      :     +- *(120) FileScan csv [uid#4373,song_id#4375,date#4378] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(121) Project [uid#4391, song_id#4393]\n      :  +- *(121) Filter ((month(date#4396) = 4) && isnotnull(uid#4391))\n      :     +- *(121) FileScan csv [uid#4391,song_id#4393,date#4396] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(122) Project [uid#4409, song_id#4411]\n      :  +- *(122) Filter ((month(date#4414) = 4) && isnotnull(uid#4409))\n      :     +- *(122) FileScan csv [uid#4409,song_id#4411,date#4414] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      :- *(123) Project [uid#4427, song_id#4429]\n      :  +- *(123) Filter ((month(date#4432) = 4) && isnotnull(uid#4427))\n      :     +- *(123) FileScan csv [uid#4427,song_id#4429,date#4432] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n      +- *(124) Project [uid#4445, song_id#4447]\n         +- *(124) Filter ((month(date#4450) = 4) && isnotnull(uid#4445))\n            +- *(124) FileScan csv [uid#4445,song_id#4447,date#4450] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/wanjiewang/PycharmProjects/music_box/music_box/processed_data/play/..., PartitionFilters: [], PushedFilters: [IsNotNull(uid)], ReadSchema: struct<uid:int,song_id:int,date:date>\n\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:56)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:371)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:150)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecute(WholeStageCodegenExec.scala:363)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.inputRDDs(SortMergeJoinExec.scala:386)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecute(WholeStageCodegenExec.scala:363)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.inputRDDs(SortMergeJoinExec.scala:386)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecute(WholeStageCodegenExec.scala:363)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.inputRDDs(SortMergeJoinExec.scala:386)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecute(WholeStageCodegenExec.scala:363)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.inputRDDs(SortMergeJoinExec.scala:386)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecute(WholeStageCodegenExec.scala:363)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinExec.inputRDDs(SortMergeJoinExec.scala:386)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.UnionExec$$anonfun$doExecute$1.apply(basicPhysicalOperators.scala:557)\n\tat org.apache.spark.sql.execution.UnionExec$$anonfun$doExecute$1.apply(basicPhysicalOperators.scala:557)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.foreach(List.scala:381)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.map(List.scala:285)\n\tat org.apache.spark.sql.execution.UnionExec.doExecute(basicPhysicalOperators.scala:557)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:371)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.SampleExec.inputRDDs(basicPhysicalOperators.scala:271)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.BaseLimitExec$class.inputRDDs(limit.scala:62)\n\tat org.apache.spark.sql.execution.LocalLimitExec.inputRDDs(limit.scala:97)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:247)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:337)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3272)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3253)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3252)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2698)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:254)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\nThis stopped SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\nsun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\nsun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\nsun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.lang.reflect.Constructor.newInstance(Constructor.java:423)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.GatewayConnection.run(GatewayConnection.java:214)\njava.lang.Thread.run(Thread.java:748)\n\nThe currently active SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\nsun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\nsun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\nsun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.lang.reflect.Constructor.newInstance(Constructor.java:423)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.GatewayConnection.run(GatewayConnection.java:214)\njava.lang.Thread.run(Thread.java:748)\n         \n\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:99)\n\tat org.apache.spark.SparkContext.broadcast(SparkContext.scala:1478)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:96)\n\tat org.apache.spark.sql.execution.datasources.FileFormat$class.buildReaderWithPartitionValues(FileFormat.scala:129)\n\tat org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:160)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:295)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:293)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDDs(DataSourceScanExec.scala:313)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:121)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.UnionExec$$anonfun$doExecute$1.apply(basicPhysicalOperators.scala:557)\n\tat org.apache.spark.sql.execution.UnionExec$$anonfun$doExecute$1.apply(basicPhysicalOperators.scala:557)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.execution.UnionExec.doExecute(basicPhysicalOperators.scala:557)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:371)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:150)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\t... 149 more\n"
     ]
    }
   ],
   "source": [
    "train_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier,GBTClassifier,RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(labelCol='label',featuresCol='features')\n",
    "# rfc = RandomForestClassifier(labelCol='label',featuresCol='features')\n",
    "# gbt = GBTClassifier(labelCol='label',featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o5118.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 220 in stage 235.0 failed 1 times, most recent failure: Lost task 220.0 in stage 235.0 (TID 44107, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillWriter.<init>(UnsafeSorterSpillWriter.java:52)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter$SpillableIterator.spill(UnsafeExternalSorter.java:536)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.spill(UnsafeExternalSorter.java:200)\n\tat org.apache.spark.memory.TaskMemoryManager.acquireExecutionMemory(TaskMemoryManager.java:180)\n\tat org.apache.spark.memory.TaskMemoryManager.allocatePage(TaskMemoryManager.java:283)\n\tat org.apache.spark.memory.TaskMemoryManager.allocatePage(TaskMemoryManager.java:310)\n\tat org.apache.spark.memory.MemoryConsumer.allocatePage(MemoryConsumer.java:117)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.acquireNewPageIfNecessary(UnsafeExternalSorter.java:383)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.insertRecord(UnsafeExternalSorter.java:407)\n\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.insertRow(UnsafeExternalRowSorter.java:135)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2166.agg_doAggregateWithKeysOutput$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2166.sort_addToSorter$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2166.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2167.findNextInnerJoinRows$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2167.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$12$$anon$2.hasNext(WholeStageCodegenExec.scala:633)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2168.findNextInnerJoinRows$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2168.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$12$$anon$2.hasNext(WholeStageCodegenExec.scala:633)\n\tat org.apache.spark.sql.execution.RowIteratorFromScala.advanceNext(RowIterator.scala:83)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinScanner.advancedStreamed(SortMergeJoinExec.scala:793)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinScanner.findNextOuterJoinRows(SortMergeJoinExec.scala:754)\n\tat org.apache.spark.sql.execution.joins.OneSideOuterIterator.advanceStream(SortMergeJoinExec.scala:916)\n\tat org.apache.spark.sql.execution.joins.OneSideOuterIterator.advanceNext(SortMergeJoinExec.scala:952)\n\tat org.apache.spark.sql.execution.RowIteratorToScala.hasNext(RowIterator.scala:68)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2294.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:363)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3272)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3253)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3252)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2698)\n\tat org.apache.spark.ml.classification.Classifier.getNumClasses(Classifier.scala:111)\n\tat org.apache.spark.ml.classification.DecisionTreeClassifier.train(DecisionTreeClassifier.scala:102)\n\tat org.apache.spark.ml.classification.DecisionTreeClassifier.train(DecisionTreeClassifier.scala:45)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillWriter.<init>(UnsafeSorterSpillWriter.java:52)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter$SpillableIterator.spill(UnsafeExternalSorter.java:536)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.spill(UnsafeExternalSorter.java:200)\n\tat org.apache.spark.memory.TaskMemoryManager.acquireExecutionMemory(TaskMemoryManager.java:180)\n\tat org.apache.spark.memory.TaskMemoryManager.allocatePage(TaskMemoryManager.java:283)\n\tat org.apache.spark.memory.TaskMemoryManager.allocatePage(TaskMemoryManager.java:310)\n\tat org.apache.spark.memory.MemoryConsumer.allocatePage(MemoryConsumer.java:117)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.acquireNewPageIfNecessary(UnsafeExternalSorter.java:383)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.insertRecord(UnsafeExternalSorter.java:407)\n\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.insertRow(UnsafeExternalRowSorter.java:135)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2166.agg_doAggregateWithKeysOutput$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2166.sort_addToSorter$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2166.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2167.findNextInnerJoinRows$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2167.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$12$$anon$2.hasNext(WholeStageCodegenExec.scala:633)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2168.findNextInnerJoinRows$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2168.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$12$$anon$2.hasNext(WholeStageCodegenExec.scala:633)\n\tat org.apache.spark.sql.execution.RowIteratorFromScala.advanceNext(RowIterator.scala:83)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinScanner.advancedStreamed(SortMergeJoinExec.scala:793)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinScanner.findNextOuterJoinRows(SortMergeJoinExec.scala:754)\n\tat org.apache.spark.sql.execution.joins.OneSideOuterIterator.advanceStream(SortMergeJoinExec.scala:916)\n\tat org.apache.spark.sql.execution.joins.OneSideOuterIterator.advanceNext(SortMergeJoinExec.scala:952)\n\tat org.apache.spark.sql.execution.RowIteratorToScala.hasNext(RowIterator.scala:68)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2294.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-977e61f18ce5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the models (its three models, so it might take some time)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdtc_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# rfc_model = rfc.fit(train_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# gbt_model = gbt.fit(train_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1160\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wanjiewang/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    319\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o5118.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 220 in stage 235.0 failed 1 times, most recent failure: Lost task 220.0 in stage 235.0 (TID 44107, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillWriter.<init>(UnsafeSorterSpillWriter.java:52)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter$SpillableIterator.spill(UnsafeExternalSorter.java:536)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.spill(UnsafeExternalSorter.java:200)\n\tat org.apache.spark.memory.TaskMemoryManager.acquireExecutionMemory(TaskMemoryManager.java:180)\n\tat org.apache.spark.memory.TaskMemoryManager.allocatePage(TaskMemoryManager.java:283)\n\tat org.apache.spark.memory.TaskMemoryManager.allocatePage(TaskMemoryManager.java:310)\n\tat org.apache.spark.memory.MemoryConsumer.allocatePage(MemoryConsumer.java:117)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.acquireNewPageIfNecessary(UnsafeExternalSorter.java:383)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.insertRecord(UnsafeExternalSorter.java:407)\n\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.insertRow(UnsafeExternalRowSorter.java:135)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2166.agg_doAggregateWithKeysOutput$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2166.sort_addToSorter$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2166.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2167.findNextInnerJoinRows$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2167.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$12$$anon$2.hasNext(WholeStageCodegenExec.scala:633)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2168.findNextInnerJoinRows$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2168.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$12$$anon$2.hasNext(WholeStageCodegenExec.scala:633)\n\tat org.apache.spark.sql.execution.RowIteratorFromScala.advanceNext(RowIterator.scala:83)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinScanner.advancedStreamed(SortMergeJoinExec.scala:793)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinScanner.findNextOuterJoinRows(SortMergeJoinExec.scala:754)\n\tat org.apache.spark.sql.execution.joins.OneSideOuterIterator.advanceStream(SortMergeJoinExec.scala:916)\n\tat org.apache.spark.sql.execution.joins.OneSideOuterIterator.advanceNext(SortMergeJoinExec.scala:952)\n\tat org.apache.spark.sql.execution.RowIteratorToScala.hasNext(RowIterator.scala:68)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2294.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:363)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3272)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3253)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3252)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2698)\n\tat org.apache.spark.ml.classification.Classifier.getNumClasses(Classifier.scala:111)\n\tat org.apache.spark.ml.classification.DecisionTreeClassifier.train(DecisionTreeClassifier.scala:102)\n\tat org.apache.spark.ml.classification.DecisionTreeClassifier.train(DecisionTreeClassifier.scala:45)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillWriter.<init>(UnsafeSorterSpillWriter.java:52)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter$SpillableIterator.spill(UnsafeExternalSorter.java:536)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.spill(UnsafeExternalSorter.java:200)\n\tat org.apache.spark.memory.TaskMemoryManager.acquireExecutionMemory(TaskMemoryManager.java:180)\n\tat org.apache.spark.memory.TaskMemoryManager.allocatePage(TaskMemoryManager.java:283)\n\tat org.apache.spark.memory.TaskMemoryManager.allocatePage(TaskMemoryManager.java:310)\n\tat org.apache.spark.memory.MemoryConsumer.allocatePage(MemoryConsumer.java:117)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.acquireNewPageIfNecessary(UnsafeExternalSorter.java:383)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.insertRecord(UnsafeExternalSorter.java:407)\n\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.insertRow(UnsafeExternalRowSorter.java:135)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2166.agg_doAggregateWithKeysOutput$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2166.sort_addToSorter$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2166.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2167.findNextInnerJoinRows$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2167.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$12$$anon$2.hasNext(WholeStageCodegenExec.scala:633)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2168.findNextInnerJoinRows$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2168.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$12$$anon$2.hasNext(WholeStageCodegenExec.scala:633)\n\tat org.apache.spark.sql.execution.RowIteratorFromScala.advanceNext(RowIterator.scala:83)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinScanner.advancedStreamed(SortMergeJoinExec.scala:793)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinScanner.findNextOuterJoinRows(SortMergeJoinExec.scala:754)\n\tat org.apache.spark.sql.execution.joins.OneSideOuterIterator.advanceStream(SortMergeJoinExec.scala:916)\n\tat org.apache.spark.sql.execution.joins.OneSideOuterIterator.advanceNext(SortMergeJoinExec.scala:952)\n\tat org.apache.spark.sql.execution.RowIteratorToScala.hasNext(RowIterator.scala:68)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2294.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n"
     ]
    }
   ],
   "source": [
    "# Train the models (its three models, so it might take some time)\n",
    "dtc_model = dtc.fit(train_data)\n",
    "# rfc_model = rfc.fit(train_data)\n",
    "# gbt_model = gbt.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc_predictions = dtc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluatoriclassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc_acc = acc_evaluator.evaluate(dtc_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
